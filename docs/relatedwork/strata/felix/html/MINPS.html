<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:svg="http://www.w3.org/2000/svg" xmlns:x86="http://www.felixcloutier.com/x86"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><link rel="stylesheet" type="text/css" href="style.css"></link><title>MINPS
		— Minimum of Packed Single-Precision Floating-Point Values</title></head><body><header><nav><ul><li><a href="./index.html">Index</a></li><li>May 2018</li></ul></nav></header><h1>MINPS
		— Minimum of Packed Single-Precision Floating-Point Values</h1>

<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op/En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>NP 0F 5D /r MINPS xmm1, xmm2/m128</td>
<td>A</td>
<td>V/V</td>
<td>SSE</td>
<td>Return the minimum single-precision floating-point values between xmm1 and xmm2/mem.</td></tr>
<tr>
<td>VEX.NDS.128.0F.WIG 5D /r VMINPS xmm1, xmm2, xmm3/m128</td>
<td>B</td>
<td>V/V</td>
<td>AVX</td>
<td>Return the minimum single-precision floating-point values between xmm2 and xmm3/mem.</td></tr>
<tr>
<td>VEX.NDS.256.0F.WIG 5D /r VMINPS ymm1, ymm2, ymm3/m256</td>
<td>B</td>
<td>V/V</td>
<td>AVX</td>
<td>Return the minimum single double-precision floating-point values between ymm2 and ymm3/mem.</td></tr>
<tr>
<td>EVEX.NDS.128.0F.W0 5D /r VMINPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>
<td>C</td>
<td>V/V</td>
<td>AVX512VL AVX512F</td>
<td>Return the minimum packed single-precision floating-point values between xmm2 and xmm3/m128/m32bcst and store result in xmm1 subject to writemask k1.</td></tr>
<tr>
<td>EVEX.NDS.256.0F.W0 5D /r VMINPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>
<td>C</td>
<td>V/V</td>
<td>AVX512VL AVX512F</td>
<td>Return the minimum packed single-precision floating-point values between ymm2 and ymm3/m256/m32bcst and store result in ymm1 subject to writemask k1.</td></tr>
<tr>
<td>EVEX.NDS.512.0F.W0 5D /r VMINPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}</td>
<td>C</td>
<td>V/V</td>
<td>AVX512F</td>
<td>Return the minimum packed single-precision floating-point values between zmm2 and zmm3/m512/m32bcst and store result in zmm1 subject to writemask k1.</td></tr></table>
<h2 id="instruction-operand-encoding">Instruction Operand Encoding<a class="anchor" href="#instruction-operand-encoding">
			¶
		</a></h2>
<table>
<tr>
<td>Op/En</td>
<td>Tuple Type</td>
<td>Operand 1</td>
<td>Operand 2</td>
<td>Operand 3</td>
<td>Operand 4</td></tr>
<tr>
<td>A</td>
<td>NA</td>
<td>ModRM:reg (r, w)</td>
<td>ModRM:r/m (r)</td>
<td>NA</td>
<td>NA</td></tr>
<tr>
<td>B</td>
<td>NA</td>
<td>ModRM:reg (w)</td>
<td>VEX.vvvv</td>
<td>ModRM:r/m (r)</td>
<td>NA</td></tr>
<tr>
<td>C</td>
<td>Full</td>
<td>ModRM:reg (w)</td>
<td>EVEX.vvvv</td>
<td>ModRM:r/m (r)</td>
<td>NA</td></tr></table>
<h3 id="description">Description<a class="anchor" href="#description">
			¶
		</a></h3>
<p>Performs a SIMD compare of the packed single-precision floating-point values in the first source operand and the second source operand and returns the minimum value for each pair of values to the destination operand.</p>
<p>If the values being compared are both 0.0s (of either sign), the value in the second operand (source operand) is returned. If a value in the second operand is an SNaN, then SNaN is forwarded unchanged to the destination (that is, a QNaN version of the SNaN is not returned).</p>
<p>If only one value is a NaN (SNaN or QNaN) for this instruction, the second operand (source operand), either a NaN or a valid floating-point value, is written to the result. If instead of this behavior, it is required that the NaN source operand (from either the first or second operand) be returned, the action of MINPS can be emulated using a sequence of instructions, such as, a comparison followed by AND, ANDN and OR.</p>
<p>EVEX encoded versions: The first source operand (the second operand) is a ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a 512/256/128-bit vector broadcasted from a 32-bit memory location. The destination operand is a ZMM/YMM/XMM register conditionally updated with writemask k1.</p>
<p>VEX.256 encoded version: The first source operand is a YMM register. The second source operand can be a YMM register or a 256-bit memory location. The destination operand is a YMM register. The upper bits (MAXVL-1:256) of the corresponding ZMM register destination are zeroed.</p>
<p>VEX.128 encoded version: The first source operand is a XMM register. The second source operand can be a XMM register or a 128-bit memory location. The destination operand is a XMM register. The upper bits (MAXVL-1:128) of the corresponding ZMM register destination are zeroed.</p>
<p>128-bit Legacy SSE version: The second source can be an XMM register or an 128-bit memory location. The destination is not distinct from the first source XMM register and the upper bits (MAXVL-1:128) of the corresponding ZMM register destination are unmodified.</p>
<h3 id="operation">Operation<a class="anchor" href="#operation">
			¶
		</a></h3>
<pre>MIN(SRC1, SRC2)
{
    IF ((SRC1 = 0.0) and (SRC2 = 0.0)) THEN DEST ←SRC2;
        ELSE IF (SRC1 = SNaN) THEN DEST ←SRC2; FI;
        ELSE IF (SRC2 = SNaN) THEN DEST ←SRC2; FI;
        ELSE IF (SRC1 &lt; SRC2) THEN DEST ←SRC1;
        ELSE DEST←SRC2;
    FI;
}
</pre>
<h4 id="vminps--evex-encoded-version-">VMINPS (EVEX encoded version)<a class="anchor" href="#vminps--evex-encoded-version-">
			¶
		</a></h4>
<pre>(KL, VL) = (4, 128), (8, 256), (16, 512)
FOR j←0 TO KL-1
    i←j * 32
    IF k1[j] OR *no writemask*
        THEN
            IF (EVEX.b = 1) AND (SRC2 *is memory*)
                THEN
                    DEST[i+31:i]←MIN(SRC1[i+31:i], SRC2[31:0])
                ELSE
                    DEST[i+31:i]←MIN(SRC1[i+31:i], SRC2[i+31:i])
            FI;
            ELSE
            IF *merging-masking* ; merging-masking
                THEN *DEST[i+31:i] remains unchanged*
                ELSE DEST[i+31:i]←0
                        ; zeroing-masking
            FI
    FI;
ENDFOR
DEST[MAXVL-1:VL] ← 0
</pre>
<h4 id="vminps--vex-256-encoded-version-">VMINPS (VEX.256 encoded version)<a class="anchor" href="#vminps--vex-256-encoded-version-">
			¶
		</a></h4>
<pre>DEST[31:0]←MIN(SRC1[31:0], SRC2[31:0])
DEST[63:32]←MIN(SRC1[63:32], SRC2[63:32])
DEST[95:64]←MIN(SRC1[95:64], SRC2[95:64])
DEST[127:96]←MIN(SRC1[127:96], SRC2[127:96])
DEST[159:128]←MIN(SRC1[159:128], SRC2[159:128])
DEST[191:160]←MIN(SRC1[191:160], SRC2[191:160])
DEST[223:192]←MIN(SRC1[223:192], SRC2[223:192])
DEST[255:224]←MIN(SRC1[255:224], SRC2[255:224])
</pre>
<h4 id="vminps--vex-128-encoded-version-">VMINPS (VEX.128 encoded version)<a class="anchor" href="#vminps--vex-128-encoded-version-">
			¶
		</a></h4>
<pre>DEST[31:0]←MIN(SRC1[31:0], SRC2[31:0])
DEST[63:32]←MIN(SRC1[63:32], SRC2[63:32])
DEST[95:64]←MIN(SRC1[95:64], SRC2[95:64])
DEST[127:96]←MIN(SRC1[127:96], SRC2[127:96])
DEST[MAXVL-1:128] ←0
</pre>
<h4 id="minps--128-bit-legacy-sse-version-">MINPS (128-bit Legacy SSE version)<a class="anchor" href="#minps--128-bit-legacy-sse-version-">
			¶
		</a></h4>
<pre>DEST[31:0]←MIN(SRC1[31:0], SRC2[31:0])
DEST[63:32]←MIN(SRC1[63:32], SRC2[63:32])
DEST[95:64]←MIN(SRC1[95:64], SRC2[95:64])
DEST[127:96]←MIN(SRC1[127:96], SRC2[127:96])
DEST[MAXVL-1:128] (Unmodified)
</pre>
<h3 id="intel-c-c++-compiler-intrinsic-equivalent">Intel C/C++ Compiler Intrinsic Equivalent<a class="anchor" href="#intel-c-c++-compiler-intrinsic-equivalent">
			¶
		</a></h3>
<pre>VMINPS __m512 _mm512_min_ps( __m512 a, __m512 b);
</pre>
<pre>VMINPS __m512 _mm512_mask_min_ps(__m512 s, __mmask16 k, __m512 a, __m512 b);
</pre>
<pre>VMINPS __m512 _mm512_maskz_min_ps( __mmask16 k, __m512 a, __m512 b);
</pre>
<pre>VMINPS __m512 _mm512_min_round_ps( __m512 a, __m512 b, int);
</pre>
<pre>VMINPS __m512 _mm512_mask_min_round_ps(__m512 s, __mmask16 k, __m512 a, __m512 b, int);
</pre>
<pre>VMINPS __m512 _mm512_maskz_min_round_ps( __mmask16 k, __m512 a, __m512 b, int);
</pre>
<pre>VMINPS __m256 _mm256_mask_min_ps(__m256 s, __mmask8 k, __m256 a, __m256 b);
</pre>
<pre>VMINPS __m256 _mm256_maskz_min_ps( __mmask8 k, __m256 a, __m25 b);
</pre>
<pre>VMINPS __m128 _mm_mask_min_ps(__m128 s, __mmask8 k, __m128 a, __m128 b);
</pre>
<pre>VMINPS __m128 _mm_maskz_min_ps( __mmask8 k, __m128 a, __m128 b);
</pre>
<pre>VMINPS __m256 _mm256_min_ps (__m256 a, __m256 b);
</pre>
<pre>MINPS __m128 _mm_min_ps (__m128 a, __m128 b);
</pre>
<h3 class="exceptions" id="simd-floating-point-exceptions">SIMD Floating-Point Exceptions<a class="anchor" href="#simd-floating-point-exceptions">
			¶
		</a></h3>
<p>Invalid (including QNaN Source Operand), Denormal</p>
<h3 class="exceptions" id="other-exceptions">Other Exceptions<a class="anchor" href="#other-exceptions">
			¶
		</a></h3>
<p>Non-EVEX-encoded instruction, see Exceptions Type 2.</p>
<p>EVEX-encoded instruction, see Exceptions Type E2.</p><footer><p>
		This UNOFFICIAL, mechanically-separated, non-verified reference is provided for convenience, but it may be
		inc<span style="opacity: 0.2">omp</span>lete or b<sub>r</sub>oke<sub>n</sub> in various obvious or non-obvious
		ways. Refer to <a href="https://software.intel.com/sites/default/files/managed/39/c5/325462-sdm-vol-1-2abcd-3abcd.pdf">Intel® 64 and IA-32 Architectures Software Developer’s Manual</a> for anything serious.
	</p></footer></body></html>
